# GNSS-RO 大气剖面反演系统 - 技术文档

> 本文档详细解读项目代码逻辑，帮助理解系统架构与实现细节，适用于中期答辩准备。

---

## 目录

1. [项目概述](#1-项目概述)
2. [系统架构](#2-系统架构)
3. [数据处理流水线](#3-数据处理流水线)
4. [模型架构](#4-模型架构)
5. [训练流程](#5-训练流程)
6. [推理与评估](#6-推理与评估)
7. [关键代码解读](#7-关键代码解读)
8. [常见问题](#8-常见问题)

---

## 1. 项目概述

### 1.1 研究背景

GNSS 无线电掩星（Radio Occultation, RO）技术通过测量 GPS 信号穿过大气层时的弯曲角，可以反演大气温度、气压、湿度等垂直剖面。传统方法基于 Abel 变换，本项目采用**条件扩散模型**实现端到端的深度学习反演。

### 1.2 技术路线

```
COSMIC-2 弯曲角观测 → 条件扩散模型 → 大气剖面 (温度/气压/湿度)
                         ↑
                    ERA5/wetPf2 作为训练真值
```

### 1.3 核心创新点

| 创新点 | 说明 |
|--------|------|
| 条件扩散模型 | 首次将 DDPM/DDIM 应用于 RO 反演 |
| 交叉注意力机制 | 增强条件信息与生成过程的交互 |
| 多变量同时反演 | 温度、气压、湿度三通道联合输出 |
| 多级质量控制 | 7 项物理约束确保数据质量 |

---

## 2. 系统架构

### 2.1 目录结构

```
.
├── ro_retrieval/              # 核心 Python 包
│   ├── config.py              # 全局配置
│   ├── data/                  # 数据处理模块
│   │   ├── dataset.py         # PyTorch Dataset
│   │   ├── process_enhanced.py# 数据处理流水线
│   │   ├── quality_control.py # 质量控制
│   │   └── era5_matching.py   # ERA5 时空匹配
│   ├── model/                 # 模型定义
│   │   ├── unet.py            # U-Net 网络
│   │   └── diffusion.py       # 扩散调度器
│   ├── training/              # 训练模块
│   │   └── trainer.py         # 训练器
│   ├── inference/             # 推理模块
│   │   └── predict.py         # 预测接口
│   └── evaluation/            # 评估模块
│       └── metrics.py         # 评估指标
├── src/                       # 入口脚本
│   ├── process_data.py        # 数据预处理
│   ├── train.py               # 训练入口
│   ├── evaluate.py            # 评估入口
│   └── run_pipeline.py        # 端到端流水线
└── Data/                      # 数据目录
    ├── Sample/                # 原始样本
    └── Processed/             # 处理后数据
```

### 2.2 模块依赖关系

```
src/train.py
    └── ro_retrieval/training/trainer.py
        ├── ro_retrieval/data/dataset.py
        ├── ro_retrieval/model/unet.py
        ├── ro_retrieval/model/diffusion.py
        └── ro_retrieval/config.py

src/evaluate.py
    ├── ro_retrieval/inference/predict.py
    └── ro_retrieval/evaluation/metrics.py
```

---

## 3. 数据处理流水线

### 3.1 数据流程图

```
┌─────────────────┐     ┌─────────────────┐
│ COSMIC atmPrf   │     │ COSMIC wetPf2   │
│ (弯曲角观测)    │     │ (温/压/湿真值)  │
└────────┬────────┘     └────────┬────────┘
         │                       │
         ▼                       ▼
┌─────────────────────────────────────────┐
│           质量控制 (7 项检查)            │
│  • 有效点数 ≥ 10                        │
│  • 穿透高度 ≥ 0.5 km                    │
│  • 温度范围 100-400 K                   │
│  • 气压单调递减                         │
│  • 湿度范围 0-0.05 kg/kg                │
│  • 温度递减率 ≤ 15 K/km                 │
│  • 弯曲角正值且非极端                   │
└────────────────────┬────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────┐
│           插值到标准高度网格             │
│     0-60 km, 301 个等间距高度层          │
└────────────────────┬────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────┐
│              数据标准化                  │
│  • 弯曲角: log10(|BA| + 1e-6)           │
│  • 输出变量: Z-Score 标准化              │
└────────────────────┬────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────┐
│         数据集划分 (70/15/15)            │
│  train_x.npy, train_y.npy               │
│  val_x.npy, val_y.npy                   │
│  test_x.npy, test_y.npy                 │
└─────────────────────────────────────────┘
```

### 3.2 关键函数说明

**文件**: `ro_retrieval/data/process_enhanced.py`

| 函数 | 行号 | 功能 |
|------|------|------|
| `process_pair_multivar()` | 58-123 | 处理单个 ATM+WET 文件对 |
| `_safe_interp()` | 36-52 | 安全插值（处理 NaN 和非单调数据）|
| `_extract_wet_labels()` | 126-192 | 从 wetPf2 提取温/压/湿 |
| `run_enhanced_pipeline()` | 300-431 | 完整处理流水线 |

**文件**: `ro_retrieval/data/quality_control.py`

| 函数 | 行号 | 功能 |
|------|------|------|
| `quality_check_profile()` | 50-94 | 检查有效点数、穿透深度 |
| `quality_check_bending_angle()` | 97-123 | 验证弯曲角正值和量级 |
| `quality_check_temperature()` | 127-145 | 检查温度范围 |
| `quality_check_pressure()` | 148-170 | 检查气压单调性 |
| `quality_check_humidity()` | 173-188 | 检查湿度范围 |
| `quality_check_lapse_rate()` | 191-215 | 检查温度递减率 |

### 3.3 数据格式

**输入 (X)**: 弯曲角剖面
- 形状: `(N, 301)` 或 `(N, 1, 301)`
- 预处理: `log10(|BA| + 1e-6)` → Z-Score

**输出 (Y)**: 大气剖面
- 单变量: `(N, 301)` - 仅温度
- 多变量: `(N, 3, 301)` - [温度, 气压, 湿度]
- 预处理: Z-Score 标准化

---

## 4. 模型架构

### 4.1 条件扩散模型原理

**前向过程 (加噪)**:
$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$

**反向过程 (去噪)**:
$$x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t, t, c) \right) + \sigma_t z$$

其中 $c$ 是条件（弯曲角），$\epsilon_\theta$ 是 U-Net 预测的噪声。

### 4.2 增强版 U-Net 架构

**文件**: `ro_retrieval/model/unet.py` (第 157-277 行)

```
输入: x_t (B, C, 301) + t (B,) + condition (B, 1, 301)
                │
                ▼
┌─────────────────────────────────────┐
│     时间嵌入 (SinusoidalTimeEmbedding)│
│     t → sin/cos 编码 → MLP → (B, 128)│
└─────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────┐
│     条件编码器                       │
│     Conv1d(1→64) → SiLU → Conv1d    │
└─────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────┐
│     编码器 (3 层)                    │
│     ┌─────────────────────────────┐ │
│     │ Level 1: ResBlock + CrossAttn│ │
│     │          + MaxPool(2)        │ │
│     └─────────────────────────────┘ │
│     ┌─────────────────────────────┐ │
│     │ Level 2: ResBlock + CrossAttn│ │
│     │          + MaxPool(2)        │ │
│     └─────────────────────────────┘ │
│     ┌─────────────────────────────┐ │
│     │ Bottleneck: ResBlock + Attn  │ │
│     └─────────────────────────────┘ │
└─────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────┐
│     解码器 (Skip Connection)         │
│     ConvTranspose + Concat + ResBlock│
└─────────────────────────────────────┘
                │
                ▼
┌─────────────────────────────────────┐
│     输出层                           │
│     Conv1d(64 → out_channels, k=1)  │
└─────────────────────────────────────┘
                │
                ▼
输出: 预测噪声 ε̂ (B, C, 301)
```

### 4.3 交叉注意力机制

**文件**: `ro_retrieval/model/unet.py` (第 75-131 行)

```python
class CrossAttention1D:
    """
    Query 来自特征图 x，Key/Value 来自条件 cond
    实现条件信息对生成过程的引导
    """
    def forward(self, x, cond):
        # x: (B, C, L) - 当前特征
        # cond: (B, C_cond, L) - 条件特征

        Q = self.to_q(x)      # Query from features
        K = self.to_k(cond)   # Key from condition
        V = self.to_v(cond)   # Value from condition

        # Multi-head attention
        attn = softmax(Q @ K.T / sqrt(d_k)) @ V

        return x + self.proj(attn)  # Residual connection
```

### 4.4 扩散调度器

**文件**: `ro_retrieval/model/diffusion.py`

| 参数 | 值 | 说明 |
|------|-----|------|
| `TIMESTEPS` | 1000 | 扩散步数 |
| `BETA_START` | 1e-4 | β 起始值 |
| `BETA_END` | 0.02 | β 终止值 |
| `DDIM_STEPS` | 50 | DDIM 加速步数 |
| `DDIM_ETA` | 0.0 | DDIM 随机性 (0=确定性) |

**DDPM vs DDIM**:
- DDPM: 1000 步完整去噪，质量最高
- DDIM: 50 步跳跃采样，速度提升 20 倍，质量接近

---

## 5. 训练流程

### 5.1 训练入口

**文件**: `src/train.py`

```bash
# 单变量训练 (仅温度)
python src/train.py --mode single --model legacy --epochs 100

# 多变量训练 (温/压/湿) - 推荐
python src/train.py --mode multi --model enhanced --epochs 100 --patience 20
```

### 5.2 训练器核心逻辑

**文件**: `ro_retrieval/training/trainer.py`

```python
class Trainer:
    def train(self):
        for epoch in range(epochs):
            # 1. 训练一个 epoch
            train_loss = self._train_one_epoch()

            # 2. 验证
            val_loss = self._validate()

            # 3. Early Stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                save_model("best.pth")
                epochs_no_improve = 0
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    break

            # 4. 定期保存检查点
            if epoch % 10 == 0:
                save_model(f"epoch_{epoch}.pth")

    def _train_one_epoch(self):
        for condition, x_0 in dataloader:
            # 采样时间步
            t = torch.randint(0, TIMESTEPS, (batch_size,))

            # 采样噪声
            noise = torch.randn_like(x_0)

            # 前向扩散: 加噪
            x_t = schedule.q_sample(x_0, t, noise)

            # 预测噪声
            noise_pred = model(x_t, t, condition)

            # 计算损失
            loss = F.mse_loss(noise_pred, noise)

            # 反向传播
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
```

### 5.3 训练超参数

**文件**: `ro_retrieval/config.py`

| 参数 | 值 | 说明 |
|------|-----|------|
| `BATCH_SIZE` | 64 | 批大小 |
| `EPOCHS` | 100 | 最大训练轮数 |
| `LEARNING_RATE` | 1e-4 | 学习率 |
| `UNET_BASE_DIM` | 64 | U-Net 基础通道数 |
| `patience` | 20 | Early Stopping 耐心值 |

### 5.4 训练输出

```
checkpoints/
├── enhanced_ro_diffusion_best.pth      # 最佳模型
├── enhanced_ro_diffusion_epoch_10.pth  # 检查点
├── enhanced_ro_diffusion_epoch_20.pth
└── ...

outputs/logs/
├── enhanced_ro_diffusion_training_log.json  # 训练日志
└── enhanced_ro_diffusion_loss_history.npy   # 损失曲线
```

---

## 6. 推理与评估

### 6.1 推理流程

**文件**: `ro_retrieval/inference/predict.py`

```python
def run_inference_ddim(model, x_input, schedule, x_mean, x_std, y_mean, y_std):
    # 1. 输入标准化
    x_norm = (x_input - x_mean) / x_std
    condition = x_norm.reshape(1, 1, -1)

    # 2. DDIM 采样 (50 步)
    pred = ddim_sample(model, condition, shape=(1, out_ch, 301),
                       schedule=schedule, ddim_steps=50, eta=0.0)

    # 3. 反标准化
    pred = pred * y_std + y_mean

    # 4. 平滑处理
    pred = savgol_filter(pred, window_length=31, polyorder=3)

    return pred
```

### 6.2 评估指标

**文件**: `ro_retrieval/evaluation/metrics.py`

| 指标 | 公式 | 说明 |
|------|------|------|
| RMSE | $\sqrt{\frac{1}{n}\sum(y_{pred}-y_{true})^2}$ | 均方根误差 |
| Bias | $\frac{1}{n}\sum(y_{pred}-y_{true})$ | 系统偏差 |
| CC | $\text{corr}(y_{pred}, y_{true})$ | 相关系数 |
| MAE | $\frac{1}{n}\sum\|y_{pred}-y_{true}\|$ | 平均绝对误差 |

### 6.3 评估命令

```bash
# DDIM 快速评估
python src/evaluate.py --sampler ddim --n_samples 50

# 指定模型
python src/evaluate.py --model_path checkpoints/enhanced_ro_diffusion_best.pth \
                       --model_type enhanced --out_channels 3
```

### 6.4 评估输出

```
outputs/evaluation/
├── evaluation_report.json    # 评估报告 (JSON)
└── ...

outputs/figures/
├── Best_RMSE_*.png          # 最佳案例可视化
├── Median_RMSE_*.png        # 中位案例可视化
└── Worst_RMSE_*.png         # 最差案例可视化
```

---

## 7. 关键代码解读

### 7.1 扩散前向过程

```python
# ro_retrieval/model/diffusion.py: 第 45-59 行
def q_sample(self, x_0, t, noise=None):
    """
    前向扩散: 给干净数据加噪
    x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * noise
    """
    if noise is None:
        noise = torch.randn_like(x_0)

    sqrt_alpha_bar = self.sqrt_alphas_cumprod[t]
    sqrt_one_minus_alpha_bar = self.sqrt_one_minus_alphas_cumprod[t]

    # 广播到正确形状
    sqrt_alpha_bar = sqrt_alpha_bar[:, None, None]
    sqrt_one_minus_alpha_bar = sqrt_one_minus_alpha_bar[:, None, None]

    return sqrt_alpha_bar * x_0 + sqrt_one_minus_alpha_bar * noise
```

### 7.2 DDIM 采样

```python
# ro_retrieval/model/diffusion.py: 第 109-153 行
def ddim_sample(model, condition, shape, schedule, ddim_steps=50, eta=0.0):
    """
    DDIM 加速采样
    - ddim_steps: 采样步数 (默认 50，比 DDPM 的 1000 快 20 倍)
    - eta: 随机性参数 (0 = 完全确定性)
    """
    # 生成时间步子集: [999, 979, 959, ..., 19, 0]
    timesteps = torch.linspace(schedule.timesteps-1, 0, ddim_steps).long()

    # 从纯噪声开始
    x = torch.randn(shape)

    for i in range(len(timesteps) - 1):
        t_curr = timesteps[i]
        t_prev = timesteps[i + 1]

        # 预测噪声
        noise_pred = model(x, t_curr, condition)

        # 预测 x_0
        alpha_bar_t = schedule.alphas_cumprod[t_curr]
        x_0_pred = (x - sqrt(1 - alpha_bar_t) * noise_pred) / sqrt(alpha_bar_t)

        # 计算 x_{t-1}
        alpha_bar_prev = schedule.alphas_cumprod[t_prev]
        sigma = eta * sqrt((1 - alpha_bar_prev) / (1 - alpha_bar_t)) * sqrt(1 - alpha_bar_t / alpha_bar_prev)

        dir_xt = sqrt(1 - alpha_bar_prev - sigma**2) * noise_pred
        x = sqrt(alpha_bar_prev) * x_0_pred + dir_xt

        if eta > 0 and t_prev > 0:
            x = x + sigma * torch.randn_like(x)

    return x
```

### 7.3 残差块

```python
# ro_retrieval/model/unet.py: 第 134-151 行
class ResBlock1D(nn.Module):
    """
    残差块: 包含时间嵌入注入
    """
    def __init__(self, in_ch, out_ch, time_emb_dim):
        self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)
        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)
        self.time_mlp = nn.Linear(time_emb_dim, out_ch)
        self.residual = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()

    def forward(self, x, t_emb):
        h = F.silu(self.conv1(x))

        # 注入时间信息
        h = h + self.time_mlp(t_emb)[:, :, None]

        h = F.silu(self.conv2(h))

        return h + self.residual(x)  # 残差连接
```

---

## 8. 常见问题

### Q1: 为什么选择扩散模型而不是传统方法？

传统 Abel 变换方法假设大气球对称，在复杂气象条件下误差较大。扩散模型可以学习复杂的非线性映射，且生成过程具有不确定性量化能力。

### Q2: DDIM 相比 DDPM 有什么优势？

| 特性 | DDPM | DDIM |
|------|------|------|
| 采样步数 | 1000 | 50 |
| 速度 | 慢 | 快 20 倍 |
| 随机性 | 有 | 可控 (eta) |
| 质量 | 最高 | 接近 DDPM |

### Q3: 交叉注意力机制的作用？

交叉注意力让模型在生成过程中动态关注条件（弯曲角）的不同部分，实现更精细的条件引导。相比简单拼接，注意力机制能捕捉更复杂的条件-输出关系。

### Q4: 如何添加新的气象变量？

1. 修改 `process_enhanced.py` 中的 `_extract_wet_labels()` 提取新变量
2. 更新 `config.py` 中的 `OUTPUT_VARIABLES` 和 `NUM_OUTPUT_VARS`
3. 调整 `quality_control.py` 添加相应的 QC 检查
4. 重新运行数据处理和训练

### Q5: 模型训练不收敛怎么办？

1. 检查数据质量：确保 QC 通过率合理
2. 降低学习率：尝试 `1e-5`
3. 增加 batch size：如果显存允许
4. 检查数据标准化：确保均值接近 0，标准差接近 1

---

## 附录: 快速命令参考

```bash
# 数据预处理
python src/process_data.py --mode wetpf2

# 训练 (多变量 + 增强模型)
python src/train.py --mode multi --model enhanced --epochs 100

# 评估
python src/evaluate.py --sampler ddim --n_samples 50

# 端到端流水线
python src/run_pipeline.py --all

# 启动 Web 界面
streamlit run ro_retrieval/app/streamlit_app.py
```

---

*文档生成时间: 2026-02-22*
